{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade simpletransformers tokenizers==0.9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/aub-mind/arabert\n",
    "!pip install pyarabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "arabert_prep = ArabertPreprocessor(model_name='aragpt2-medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://github.com/UBC-NLP/aoc_id/raw/master/data/train/MultiTrain.Shuffled.csv\"\n",
    "!head -n 3 MultiTrain.Shuffled.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "eval = []\n",
    "\n",
    "dialect = {\n",
    "    'MSA': '[MSA] ',\n",
    "    'DIAL_EGY': \"[EGYPTIAN] \",\n",
    "    'DIAL_LEV': \"[LEVANTINE] \",\n",
    "    'DIAL_GLF': \"[GULF] \"\n",
    "}\n",
    "\n",
    "with open(\"./MultiTrain.Shuffled.csv\", \"r\") as prompts:\n",
    "  rdr = csv.reader(prompts)\n",
    "  lines = 0\n",
    "  for line in rdr:\n",
    "    lines += 1\n",
    "    if len(line) == 3 and len(line[0]) > 0:\n",
    "      if random.random() > 0.4:\n",
    "        train.append(dialect[line[1]] + arabert_prep.preprocess(line[2]) + '<|endoftext|>')\n",
    "      elif random.random() > 0.2:\n",
    "        test.append(dialect[line[1]] + arabert_prep.preprocess(line[2])  + '<|endoftext|>')\n",
    "      else:\n",
    "        eval.append(dialect[line[1]] + arabert_prep.preprocess(line[2])  + '<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/jslg6fzxeu47flu/DART.zip\n",
    "!unzip DART.zip\n",
    "!head -n 5 DART/cf-data/EGY.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialect in [['EGY', '[EGYPTIAN] '], ['GLF', '[GULF] '], ['LEV', '[LEVANTINE] '], ['MGH', '[MAGHREBI] ']]:\n",
    "  with open(\"./DART/cf-data/\" + dialect[0] + \".txt\", \"r\") as prompts:\n",
    "    rdr = csv.reader(prompts, delimiter='\\t')\n",
    "    lines = 0\n",
    "    for line in rdr:\n",
    "      lines += 1\n",
    "      if line == 1:\n",
    "        continue\n",
    "      if len(line) == 3:\n",
    "        if random.random() > 0.4:\n",
    "          train.append(dialect[1] + arabert_prep.preprocess(line[2])  + '<|endoftext|>')\n",
    "        elif random.random() > 0.2:\n",
    "          test.append(dialect[1] + arabert_prep.preprocess(line[2])  + '<|endoftext|>')\n",
    "        else:\n",
    "          eval.append(dialect[1] + arabert_prep.preprocess(line[2])  + '<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ryancotterell/arabic_dialect_annotation\n",
    "!gunzip arabic_dialect_annotation/annotated_data.tar.gz\n",
    "!tar -xvf arabic_dialect_annotation/annotated_data.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls annotated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 annotated_data/gulf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialect in [['egyptian', '[EGYPTIAN] '], ['gulf', '[GULF] '], ['levantine', '[LEVANTINE] '], ['maghrebi', '[MAGHREBI] '], ['msa', '[MSA] ']]:\n",
    "  with open(\"./annotated_data/\" + dialect[0], \"r\") as prompts:\n",
    "    rdr = csv.reader(prompts, delimiter='\\t')\n",
    "    lines = 0\n",
    "    for line in rdr:\n",
    "      lines += 1\n",
    "      if line == 1:\n",
    "        continue\n",
    "      if len(line) == 2:\n",
    "        if random.random() > 0.4:\n",
    "          train.append(dialect[1] + arabert_prep.preprocess(line[1])  + '<|endoftext|>')\n",
    "        elif random.random() > 0.2:\n",
    "          test.append(dialect[1] + arabert_prep.preprocess(line[1]) + '<|endoftext|>')\n",
    "        else:\n",
    "          eval.append(dialect[1] + arabert_prep.preprocess(line[1]) + '<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('./train.txt', 'w').write(\"\\n\".join(train))\n",
    "open('./test.txt', 'w').write(\"\\n\".join(test))\n",
    "open('./eval.txt', 'w').write(\"\\n\".join(test))\n",
    "len(train) // 117500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.language_modeling import LanguageModelingModel\n",
    "\n",
    "train_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"train_batch_size\": 8, # multiples of 8 are best; 16 currently hits a gpu limit\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"fp16\": False,\n",
    "    \"mlm\": False,\n",
    "}\n",
    "\n",
    "ft_model = LanguageModelingModel('gpt2', 'aubmindlab/aragpt2-medium', args=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialect tokens\n",
    "ft_model.tokenizer.add_tokens([\"[EGYPTIAN]\", \"[MSA]\", \"[LEVANTINE]\", \"[GULF]\", \"[MAGHREBI]\"])\n",
    "ft_model.model.resize_token_embeddings(len(ft_model.tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.train_model(\"./train.txt\", eval_file=\"./test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.eval_model(\"./eval.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.tokenizer.save_pretrained(\"./dialects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.model.save_pretrained(\"./dialects\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
