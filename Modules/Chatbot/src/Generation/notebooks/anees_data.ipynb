{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anees_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAex3IN8DWUn",
        "outputId": "a7a95b85-3f54-48a8-ed01-c7271f659c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/anees\")"
      ],
      "metadata": {
        "id": "YtH0PnJaDmTE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePjuaC5JE8Cl",
        "outputId": "0975e5eb-2ebe-4d88-c381-5594f6830bf4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 776.7 MB 5.1 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 63.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 298 kB 74.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 60.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 47.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 62.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 71.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 73.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 75.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 75.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 72.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.7.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from transformers import GPT2TokenizerFast\n",
        "from src.preprocess import preprocess\n",
        "\n",
        "MODEL_NAME = '/content/drive/MyDrive/arzgpt2-corpus/run_clm_hageen'\n",
        "DATA_PATH = '/content/drive/MyDrive/anees/data'"
      ],
      "metadata": {
        "id": "Hwv0J1eSDk2o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_arabic_data(tokenizer, prefix):\n",
        "  print(f\"Loading the {prefix} utters...\")\n",
        "\n",
        "  dials = []\n",
        "  with open(f\"{DATA_PATH}/{prefix}_utters.json\", 'r') as f:\n",
        "    dials = json.load(f)\n",
        "  \n",
        "  print(f\"Tokenize the {prefix} utters...\")\n",
        "  ids = []\n",
        "  for dial in tqdm(dials):\n",
        "    dial_ids = []\n",
        "    for utter in dial:\n",
        "      proecessed_utter = preprocess(utter)\n",
        "      tokens = tokenizer.tokenize(proecessed_utter)\n",
        "      token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "      dial_ids.append(token_ids)\n",
        "    ids.append(dial_ids)\n",
        "  \n",
        "  assert len(ids) == len(dials)\n",
        "  with open(f\"{DATA_PATH}/{prefix}_ids.json\", 'w') as f:\n",
        "    json.dump(ids, f)\n",
        "  print(f\"Saved the {prefix} ids.\")"
      ],
      "metadata": {
        "id": "zAysI_leDvil"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2TokenizerFast.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "HZmlhpgNEIoq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_arabic_data(tokenizer, 'egy_test')\n",
        "tokenize_arabic_data(tokenizer, 'egy_train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR-sc9ypEJqg",
        "outputId": "d6604db8-fb78-4432-ece6-79f67b930d37"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the egy_test utters...\n",
            "Tokenize the egy_test utters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:00<00:00, 2356.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved the egy_test ids.\n",
            "Loading the egy_train utters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize the egy_train utters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:00<00:00, 2728.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved the egy_train ids.\n"
          ]
        }
      ]
    }
  ]
}