{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import tokenization\n",
    "import preprocess\n",
    "import ner\n",
    "import verb_extraction\n",
    "import stemming\n",
    "import time_extract\n",
    "import content_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سبعه 0.25\n"
     ]
    }
   ],
   "source": [
    "bagOfWords = time_extract.numbers_bag_of_words()\n",
    "index, editdistance = time_extract.get_closest_word_with_threshold(\"ساعه\", bagOfWords)\n",
    "print (bagOfWords[index], editdistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLU(text):\n",
    "    #Preprocessing\n",
    "    text = preprocess.pre_process(text)\n",
    "    #Tokenization\n",
    "    tokens = tokenization.get_tokens(text)\n",
    "    # NER\n",
    "    ents = ner.get_ents(tokens)\n",
    "    #Part of Speech and Stemming\n",
    "    tokens_verb_noun = verb_extraction.extract_stem_verb(tokens,ents)\n",
    "    tokens_verb_noun = stemming.stem(tokens_verb_noun)\n",
    "    return text , tokens ,ents , tokens_verb_noun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Sherif\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ahmed Sherif\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LinearSVC from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ahmed Sherif\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = input()\n",
    "text , tokens ,ents , tokens_verb_noun = NLU(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "def get_movie (text):\n",
    "    return text.split('(')[0].lower().strip()\n",
    "def get_movies_content (text, tokens, tokens_verb_noun):\n",
    "    movies_bag_of_words_eng = ['action','adventure','animation','children','comedy','crime','documentary','drama','fantasy','horror','musical','mystery','romance','sci-fi','war','western']\n",
    "    movies_bag_of_words_ar = ['اكشن','مغامره','انيميشن','اطفال','كوميدي','جريمه','وثايقي','دراما','خيال','رعب','موسيقي','غموض','رومانسي','علمي','حروب','ويستيرن']\n",
    "    categories = []\n",
    "    movie = re.findall(\"[a-zA-Z]*\", text) \n",
    "    movie = \" \".join(movie)\n",
    "    movie = re.sub(' +', ' ',movie).lower().strip()\n",
    "    df = pd.read_csv(\"Task_data/movies.csv\")\n",
    "    movies = df[\"title\"].apply(func=get_movie)\n",
    "    print(movie)\n",
    "    index, distance = time_extract.get_closest_word_with_threshold(movie, movies, 0.4)\n",
    "    if index != -1:\n",
    "        movie = movies[index]\n",
    "    else:\n",
    "         movie = \"\"\n",
    "    for index, word in enumerate(tokens):\n",
    "        if tokens_verb_noun[index][1] == 'n':\n",
    "            index, distance = time_extract.get_closest_word_with_threshold(word,movies_bag_of_words_ar, 0.4)\n",
    "            if index != -1:\n",
    "                categories.append([movies_bag_of_words_eng[index], 1 - distance])\n",
    "    return movie, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toy store\n",
      "('', [])\n"
     ]
    }
   ],
   "source": [
    "print(get_movies_content(text, tokens, tokens_verb_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4416bc9836c12781b1e5ff1e266afc9f29e38369dcfeb27a2853c274cac55a02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
