{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('../data_preprocessing/preprocessed_data/data_main.csv',encoding='utf-8')\n",
    "new_data = pd.read_csv('new/final.csv',encoding='utf-8')\n",
    "data = pd.concat([data,new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2262.0</td>\n",
       "      <td>كون خير</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>639.0</td>\n",
       "      <td>صبح وانا جوايا ميه حسره ووجع قلب محسيتهمش سنتي...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5582.0</td>\n",
       "      <td>تعالجتي دكتور طيب تري انتي وبا هلع وقلق واعراض...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1712.0</td>\n",
       "      <td>🎀 حديثك يغرقني فرح 💞 سحر خانوم 🌈</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>672.0</td>\n",
       "      <td>اسف رد خارجيتنا ضعيف ومهزوز ضرب عثماني واصعقه ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              TWEET    LABEL  \\\n",
       "0      2262.0                                            كون خير     fear   \n",
       "1       639.0  صبح وانا جوايا ميه حسره ووجع قلب محسيتهمش سنتي...  sadness   \n",
       "2      5582.0  تعالجتي دكتور طيب تري انتي وبا هلع وقلق واعراض...  sadness   \n",
       "3      1712.0                   🎀 حديثك يغرقني فرح 💞 سحر خانوم 🌈      joy   \n",
       "4       672.0  اسف رد خارجيتنا ضعيف ومهزوز ضرب عثماني واصعقه ...    anger   \n",
       "\n",
       "  pos_neg  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tweet = list(data['TWEET'])[10000:]\n",
    "label = list(data['pos_neg'])[10000:]\n",
    "for i in range(len(tweet)):\n",
    "    if tweet[i] is np.nan:\n",
    "        tweet[i] = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweet, label, test_size=0.2, random_state=0)\n",
    "vectorizer = TfidfVectorizer(encoding='utf-8')\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#text_classifier = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "#text_classifier = LinearSVC(random_state=0,C=0.2)\n",
    "text_classifier = LogisticRegression(random_state=0,n_jobs=-1,max_iter=1000)\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440377149195785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = text_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = vectorizer.transform(tweet)\n",
    "text_classifier.fit(tweet, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9039933444259567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = text_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = f'../models/sentmental_pos_neg_model.sav'\n",
    "pickle.dump(text_classifier, open(filename, 'wb'))\n",
    "filename = f'../models/tfidf_pos_neg_model.sav'\n",
    "pickle.dump(vectorizer, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
